{
    "type": [
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        2,
        3,
        3,
        3,
        3,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        2,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        3,
        3,
        3,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2
    ],
    "data": [
        "                    data=control_clipped, ",
        "+ ",
        "                    FUN = mean,",
        "+ ",
        "                    R = 10000,",
        "+ ",
        "                    na.rm= TRUE)",
        "Error in tapply(seq_len(n), as.numeric(strata)) : \n  arguments must have same length\n",
        "> ",
        "control_clipped_no_fern = na.omit(droplevels(",
        "+ ",
        "  subset( control_clipped, != \"fern\")))",
        "Error: unexpected '!=' in:\n\"control_clipped_no_fern = na.omit(droplevels(\n  subset( control_clipped, !=\"\n",
        "> ",
        "control_clipped_no_fern = na.omit(droplevels(",
        "+ ",
        "  control_clipped, != \"fern\"))",
        "Error: unexpected '!=' in:\n\"control_clipped_no_fern = na.omit(droplevels(\n  control_clipped, !=\"\n",
        "> ",
        "p= rnorm(control ~ pine, data= control_clipped)",
        "Error in rnorm(control ~ pine, data = control_clipped) : \n  unused argument (data = control_clipped)\n",
        "> ",
        "p= rnorm(control ~ pine, control_clipped)",
        "Error in rnorm(control ~ pine, control_clipped) : invalid arguments\n",
        "> ",
        "control= subset(control_clipped, treatment== \"control\")",
        "> ",
        "View(control)",
        "> ",
        "clipped= subset(control_clipped, treatment== \"clipped\")",
        "> ",
        "View(clipped)",
        "> ",
        "p= rnorm(control$pine)",
        "> ",
        "q= rnorm(clipped$pine)",
        "> ",
        "tree_boot= two.boot(p, q, ",
        "+ ",
        "                    FUN = mean,",
        "+ ",
        "                    R = 10000,",
        "+ ",
        "                    na.rm= TRUE)",
        "> ",
        "quantile(tree_boot$t, c(0.025, 0.975))",
        "      2.5%      97.5% \n-0.5524543  1.1644090 \n",
        "> ",
        "boot.ci(tree_boot)",
        "Error in boot.ci(tree_boot) : could not find function \"boot.ci\"\n",
        "> ",
        "require(boot.ci)",
        "Loading required package: boot.ci\n",
        "Warning message:\n",
        "In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :",
        "\n ",
        " there is no package called ‘boot.ci’\n",
        "> ",
        "boot.ci()",
        "Error in boot.ci() : could not find function \"boot.ci\"\n",
        "> ",
        "library(boot)",
        "> ",
        "boot.ci(tree_boot)",
        "BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 10000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = tree_boot)\n\nIntervals : \nLevel      Normal              Basic         \n95%   (-0.6221,  1.0945 )   (-0.7041,  1.0134 )  \n\nLevel     Percentile            BCa          \n95%   (-0.5529,  1.1645 )   (-0.5067,  1.2364 )  \nCalculations and Intervals on Original Scale\n",
        "Warning message:\n",
        "In boot.ci(tree_boot) :",
        "\n ",
        " bootstrap variances needed for studentized intervals\n",
        "> ",
        "quantile(tree_boot$t, c(0.025, 0.975))",
        "      2.5%      97.5% \n-0.5524543  1.1644090 \n",
        "> ",
        "sd(tree_boot$t)",
        "[1] 0.4379031\n",
        "> ",
        "dat_all = merge(",
        "+ ",
        "  bird_dat, ",
        "+ ",
        "  hab_dat,",
        "+ ",
        "  by = c(\"basin\", \"sub\"))",
        "> ",
        "head(dat_all[, c(\"b.sidi\", \"s.sidi\")])",
        "      b.sidi s.sidi\n1 0.06678912   0.12\n2 0.06509689   0.34\n3 0.06092608   0.78\n4 0.06012721   0.57\n5 0.04112905   0.84\n6 0.06086158   0.73\n",
        "> ",
        "View(no_removed)",
        "> ",
        "View(dat_all)",
        "> ",
        "b_sidi_mean = mean(dat_all$b.sidi, na.rm = TRUE)",
        "> ",
        "b_sidi_sd   = sd(dat_all$b.sidi, na.rm = TRUE)",
        "> ",
        "dat_all$b.sidi.standardized = ",
        "+ ",
        "  (dat_all$b.sidi - b_sidi_mean)/b_sidi_sd",
        "> ",
        "View(dat_all)",
        "> ",
        "s_sidi_mean = mean(dat_all$s.sidi, na.rm = TRUE)",
        "> ",
        "s_sidi_sd   = sd(dat_all$s.sidi, na.rm = TRUE)",
        "> ",
        "dat_all$s.sidi.standardized = (dat_all$s.sidi - s_sidi_mean)/s_sidi_sd",
        "> ",
        "mean(dat_all$b.sidi.standardized)",
        "[1] 7.166938e-17\n",
        "> ",
        "sd(dat_all$b.sidi.standardized)",
        "[1] 1\n",
        "> ",
        "mean(dat_all$s.sidi.standardized)",
        "[1] 2.984718e-17\n",
        "> ",
        "sd(dat_all$s.sidi.standardized)",
        "[1] 1\n",
        "> ",
        "m=10000",
        "> ",
        "result_mc= numeric(m)",
        "> ",
        "for(i in 1:m)",
        "+ ",
        "{",
        "+ ",
        "  index_1 = sample(...,,)",
        "+ ",
        "  ",
        "+ ",
        "  # ... your loop code ...  ",
        "+ ",
        "  ",
        "+ ",
        "  result_mc[i] = coef(fit_resampled_i)[2]",
        "+ ",
        "} ",
        "Error in sample(..., , ) : '...' used in an incorrect context\n",
        "> ",
        "  lm(dat_all) ",
        "Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : \n  NA/NaN/Inf in 'y'\n",
        "In addition: ",
        "Warning message:\n",
        "In storage.mode(v) <- \"double\" :",
        " NAs introduced by coercion\n",
        "> ",
        " lm(dat_all$b.sidi.standardized)",
        "Error in formula.default(object, env = baseenv()) : invalid formula\n",
        "> ",
        "lm(formula= b.sidi.standardized~ s.sidi.standardized, data= dat_all) ",
        "\nCall:\nlm(formula = b.sidi.standardized ~ s.sidi.standardized, data = dat_all)\n\nCoefficients:\n        (Intercept)  s.sidi.standardized  \n          6.081e-17           -5.831e-01  \n\n",
        "> ",
        "for(i in 1:m)",
        "+ ",
        "{",
        "+ ",
        "  index_1 = sample(dat_all)",
        "+ ",
        "  ",
        "+ ",
        "  slope_observed= lm(formula= b.sidi.standardized~ s.sidi.standardized, ",
        "+ ",
        "                     data= dat_all) ",
        "+ ",
        "  ",
        "+ ",
        "  result_mc[i] = coef(fit_resampled_i)[2]",
        "+ ",
        "} ",
        "Error in coef(fit_resampled_i) : object 'fit_resampled_i' not found\n",
        "> ",
        "set.seed(123)",
        "> ",
        "index_1 = sample(nrow(dat_1), replace = TRUE)",
        "Error in nrow(dat_1) : object 'dat_1' not found\n",
        "> ",
        "fit_1 = lm(b.sidi ~ s.sidi, data = dat_all)",
        "> ",
        "coef(fit_1)",
        "(Intercept)      s.sidi \n 0.07116980 -0.02437131 \n",
        "> ",
        "",
        "> ",
        "set.seed(123)",
        "> ",
        "index_1 = sample(nrow(dat_1), replace = TRUE)",
        "Error in nrow(dat_1) : object 'dat_1' not found\n",
        "> ",
        "fit_1 = lm(b.sidi ~ s.sidi, data = dat_all)",
        "> ",
        "coef(fit_1)",
        "(Intercept)      s.sidi \n 0.07116980 -0.02437131 \n",
        "> ",
        "",
        "> ",
        "slope_observed = coef(fit_1)[2]",
        "> ",
        "",
        "> ",
        "dat_1 = ",
        "+ ",
        "  subset(",
        "+ ",
        "    dat_all,",
        "+ ",
        "    select = c(b.sidi, s.sidi))",
        "> ",
        "",
        "> ",
        "set.seed(123)",
        "> ",
        "index_1 = sample(nrow(dat_1), replace = TRUE)",
        "> ",
        "index_2 = sample(nrow(dat_1), replace = TRUE)",
        "> ",
        "",
        "> ",
        "dat_resampled_i = ",
        "+ ",
        "  data.frame(",
        "+ ",
        "    b.sidi = dat_1$b.sidi[index_1],",
        "+ ",
        "    s.sidi = dat_1$s.sidi[index_2]",
        "+ ",
        "  )",
        "> ",
        "",
        "> ",
        "fit_resampled_i = lm(b.sidi ~ s.sidi, data = dat_resampled_i)",
        "> ",
        "slope_resampled_i = coef(fit_resampled_i)[2]",
        "> ",
        "print(slope_resampled_i)",
        "     s.sidi \n0.006235381 \n",
        "> ",
        "print(slope_resampled_i)",
        "     s.sidi \n0.006235381 \n",
        "> ",
        "for(i in 1:m)",
        "+ ",
        "{",
        "+ ",
        "  index_1 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  index_2 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  ",
        "+ ",
        "  dat_resampled_i = ",
        "+ ",
        "    data.frame(",
        "+ ",
        "      b.sidi = dat_1$b.sidi[index_1],",
        "+ ",
        "      s.sidi = dat_1$s.sidi[index_2]",
        "+ ",
        "    )",
        "+ ",
        "  ",
        "+ ",
        "  fit_resampled_i = lm(b.sidi ~ s.sidi, data = dat_resampled_i)",
        "+ ",
        "  slope_resampled_i = coef(fit_resampled_i)[2]",
        "+ ",
        "  ",
        "+ ",
        "  slope_observed = coef(fit_1)[2]",
        "+ ",
        "  ",
        "+ ",
        "  result_mc[i] = coef(fit_resampled_i)[2]",
        "+ ",
        "} ",
        "> ",
        "hist(",
        "+ ",
        "  result_mc,",
        "+ ",
        "  main = \"Null Distribution of Regression Slope\",",
        "+ ",
        "  xlab = \"Slope Parameter\")",
        "> ",
        "abline(v = slope_observed, lty = 2, col = \"red\", lwd = 2)",
        "> ",
        "hist(",
        "+ ",
        "  result_mc,",
        "+ ",
        "  main = \"Null Distribution of Regression Slope\",",
        "+ ",
        "  xlab = \"Slope Parameter\")",
        "> ",
        "abline(v = slope_observed, lty = 1, col = \"blue\", lwd = 2)",
        "> ",
        "quantile(result_mc, c(.05))",
        "         5% \n-0.01320388 \n",
        "> ",
        "hist(",
        "+ ",
        "  result_mc,",
        "+ ",
        "  main = \"Null Distribution of Regression Slope\",",
        "+ ",
        "  xlab = \"Slope Parameter\")",
        "> ",
        "abline(v = slope_observed, lty = 1, col = \"blue\", lwd = 2)",
        "> ",
        "abline(v= quantile(result_mc, c(.05)), lty = 2, col = \"red\", lwd = 2)",
        "> ",
        "set.seed(345)",
        "> ",
        "index_1 = sample(nrow(dat_1), replace = TRUE)",
        "> ",
        "",
        "> ",
        "dat_boot = dat_1[index_1, ]",
        "> ",
        "head(dat_boot)",
        "       b.sidi s.sidi\n29 0.08263485   0.00\n23 0.05705873   0.62\n19 0.05820778   0.54\n21 0.07254766   0.41\n18 0.06365076   0.49\n28 0.06284046   0.36\n",
        "> ",
        "fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)",
        "> ",
        "",
        "> ",
        "coef(fit_bs1)",
        "(Intercept)      s.sidi \n 0.07489893 -0.03146039 \n",
        "> ",
        "hist(",
        "+ ",
        "  result_boot,",
        "+ ",
        "  main = \"Mike's Alternative Distribution of Regression Slope\",",
        "+ ",
        "  xlab = \"Slope Parameter\")",
        "Error in hist(result_boot, main = \"Mike's Alternative Distribution of Regression Slope\",  : \n  object 'result_boot' not found\n",
        "> ",
        "m=10000",
        "> ",
        "result_mc= numeric(m)",
        "> ",
        "",
        "> ",
        "for(i in 1:m)",
        "+ ",
        "{",
        "+ ",
        "  index_1 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  ",
        "+ ",
        "  dat_boot = dat_1[index_1, ]",
        "+ ",
        "  ",
        "+ ",
        "  fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)",
        "+ ",
        "  ",
        "+ ",
        "  slope_observed = coef(fit_bs1)[2]",
        "+ ",
        "  ",
        "+ ",
        "  result_boot[i] = coef(fit_bs1)[2]",
        "+ ",
        "} ",
        "Error: object 'result_boot' not found\n",
        "> ",
        "m=10000",
        "> ",
        "result_mc= numeric(m)",
        "> ",
        "",
        "> ",
        "for(i in 1:m)",
        "+ ",
        "{",
        "+ ",
        "  index_1 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  ",
        "+ ",
        "  dat_boot = dat_1[index_1, ]",
        "+ ",
        "  ",
        "+ ",
        "  fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)",
        "+ ",
        "  ",
        "+ ",
        "  slope_observed = coef(fit_bs1)[2]",
        "+ ",
        "  ",
        "+ ",
        "  result_boot = coef(fit_bs1)[2]",
        "+ ",
        "} ",
        "> ",
        "hist(",
        "+ ",
        "  result_boot,",
        "+ ",
        "  main = \"Mike's Alternative Distribution of Regression Slope\",",
        "+ ",
        "  xlab = \"Slope Parameter\")",
        "> ",
        "abline(v = slope_observed, lty = 2, col = \"red\", lwd = 2)",
        "> ",
        "abline(v = 0, lty = 2, col = 1, lwd = 2)",
        "> ",
        "for(i in 1:m)",
        "+ ",
        "{",
        "+ ",
        "  index_1 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  index_2 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  ",
        "+ ",
        "  dat_boot =  data.frame(",
        "+ ",
        "    b.sidi = dat_1$b.sidi[index_1],",
        "+ ",
        "    s.sidi = dat_1$s.sidi[index_2]",
        "+ ",
        "  )",
        "+ ",
        "  ",
        "+ ",
        "  fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)",
        "+ ",
        "  ",
        "+ ",
        "  slope_observed = coef(fit_bs1)[2]",
        "+ ",
        "  ",
        "+ ",
        "  result_boot = coef(fit_bs1)[2]",
        "+ ",
        "} ",
        "> ",
        "hist(",
        "+ ",
        "  result_boot,",
        "+ ",
        "  main = \"Alternative Distribution of Regression Slope\",",
        "+ ",
        "  xlab = \"Slope Parameter\")",
        "> ",
        "abline(v = slope_observed, lty = 2, col = \"red\", lwd = 2)",
        "> ",
        "abline(v = 0, lty = 2, col = 1, lwd = 2)",
        "> ",
        "for(i in 1:m)",
        "+ ",
        "{",
        "+ ",
        "  index_1 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  index_2 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  ",
        "+ ",
        "  dat_boot =  data.frame(",
        "+ ",
        "    b.sidi = dat_1$b.sidi[index_1],",
        "+ ",
        "    s.sidi = dat_1$s.sidi[index_2]",
        "+ ",
        "  )",
        "+ ",
        "  ",
        "+ ",
        "  fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)",
        "+ ",
        "  slope_resampled_i = coef(fit_bs1)[2]",
        "+ ",
        "  ",
        "+ ",
        "  slope_observed = coef(fit_1)[2]",
        "+ ",
        "  ",
        "+ ",
        "  result_boot = coef(fit_bs1)[2]",
        "+ ",
        "} ",
        "> ",
        "hist(",
        "+ ",
        "  result_boot,",
        "+ ",
        "  main = \"Alternative Distribution of Regression Slope\",",
        "+ ",
        "  xlab = \"Slope Parameter\")",
        "> ",
        "abline(v = slope_observed, lty = 2, col = \"red\", lwd = 2)",
        "> ",
        "abline(v = 0, lty = 2, col = 1, lwd = 2)",
        "> ",
        "set.seed(345)",
        "> ",
        "index_1 = sample(nrow(dat_1), replace = TRUE)",
        "> ",
        "",
        "> ",
        "dat_boot = dat_1[index_1, ]",
        "> ",
        "head(dat_boot)",
        "       b.sidi s.sidi\n29 0.08263485   0.00\n23 0.05705873   0.62\n19 0.05820778   0.54\n21 0.07254766   0.41\n18 0.06365076   0.49\n28 0.06284046   0.36\n",
        "> ",
        "",
        "> ",
        "fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)",
        "> ",
        "",
        "> ",
        "coef(fit_bs1)",
        "(Intercept)      s.sidi \n 0.07489893 -0.03146039 \n",
        "> ",
        "",
        "> ",
        "m=10000",
        "> ",
        "result_mc= numeric(m)",
        "> ",
        "",
        "> ",
        "for(i in 1:m)",
        "+ ",
        "{",
        "+ ",
        "  index_1 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  index_2 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  ",
        "+ ",
        "  dat_boot =  data.frame(",
        "+ ",
        "    b.sidi = dat_1$b.sidi[index_1],",
        "+ ",
        "    s.sidi = dat_1$s.sidi[index_2]",
        "+ ",
        "  )",
        "+ ",
        "  ",
        "+ ",
        "  fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)",
        "+ ",
        "  slope_resampled_i = coef(fit_bs1)[2]",
        "+ ",
        "  ",
        "+ ",
        "  slope_observed = coef(fit_1)[2]",
        "+ ",
        "  ",
        "+ ",
        "  result_boot = coef(fit_bs1)[2]",
        "+ ",
        "} ",
        "> ",
        "hist(",
        "+ ",
        "  result_boot,",
        "+ ",
        "  main = \"Alternative Distribution of Regression Slope\",",
        "+ ",
        "  xlab = \"Slope Parameter\")",
        "> ",
        "abline(v = slope_observed, lty = 2, col = \"red\", lwd = 2)",
        "> ",
        "abline(v = 0, lty = 2, col = 1, lwd = 2)",
        "> ",
        "set.seed(345)",
        "> ",
        "index_1 = sample(nrow(dat_1), replace = TRUE)",
        "Error in nrow(dat_1) : object 'dat_1' not found\n",
        "> ",
        "fit_1 = lm(b.sidi ~ s.sidi, data = dat_all)",
        "Error in is.data.frame(data) : object 'dat_all' not found\n",
        "> ",
        "require(here)",
        "> ",
        "veg_dat = read.csv(here(\"data\", \"vegdata.csv\"))",
        "> ",
        "bird_dat = read.csv(here(\"data\", \"bird.sub.csv\"))",
        "> ",
        "hab_dat = read.csv(here(\"data\", \"hab.sub.csv\"))",
        "> ",
        "",
        "> ",
        "install.packages(\"palmerpenguins\")",
        "trying URL 'https://cran.rstudio.com/bin/macosx/contrib/4.2/palmerpenguins_0.1.1.tgz'\n",
        "Content type 'application/x-gzip'",
        " length 3003192 bytes (2.9 MB)\n",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "=",
        "\n",
        "downloaded 2.9 MB\n\n",
        "\nThe downloaded binary packages are in\n\t/var/folders/gw/9wgpkps10qn5hx0_w3308vxh0000gn/T//RtmpAxzxXP/downloaded_packages\n",
        "> ",
        "install.packages(\"here\")",
        "Error in install.packages : Updating loaded packages\n",
        "> ",
        "require(palmerpenguins)",
        "Loading required package: palmerpenguins\n",
        "> ",
        "require(here)",
        "> ",
        "penguins = data.frame(penguins)",
        "> ",
        "",
        "> ",
        "no_gentoo = na.omit(droplevels(",
        "+ ",
        "  subset(penguins, species != \"Gentoo\")))",
        "> ",
        "",
        "> ",
        "t.test(flipper_length_mm ~ species, data = no_gentoo, alternative = \"less\")",
        "\n\tWelch Two Sample t-test\n\ndata:  flipper_length_mm by species\nt = -5.6115, df = 120.88, p-value = 6.483e-08\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is less than 0\n95 percent confidence interval:\n      -Inf -4.030952\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               190.1027                195.8235 \n\n",
        "> ",
        "",
        "> ",
        "install.packages(\"boot\")",
        "Error in install.packages : Updating loaded packages\n",
        "> ",
        "library(boot)",
        "> ",
        "require(simpleboot)",
        "> ",
        "require(here)",
        "> ",
        "",
        "> ",
        "adelie_dat= na.omit(droplevels(",
        "+ ",
        "  subset(no_gentoo, species != \"Chinstrap\")))",
        "> ",
        "chinstrap_dat= na.omit(droplevels(",
        "+ ",
        "  subset(no_gentoo, species != \"Adelie\")))",
        "> ",
        "",
        "> ",
        "x = rnorm(adelie_dat$flipper_length_mm)",
        "> ",
        "y = rnorm(chinstrap_dat$flipper_length_mm)",
        "> ",
        "",
        "> ",
        "pen_boot= two.boot(x, ",
        "+ ",
        "         y, ",
        "+ ",
        "         data= no_gentoo, ",
        "+ ",
        "         FUN = mean,",
        "+ ",
        "         R = 10000,",
        "+ ",
        "         na.rm= TRUE)",
        "> ",
        "str(pen_boot)",
        "List of 12\n $ t0       : num -0.147\n $ t        : num [1:10000, 1] -0.2782 0.0636 -0.1859 -0.1514 -0.015 ...\n $ R        : num 10000\n $ data     : num [1:214] -0.7849 -0.2795 -0.1615 -0.2906 -0.0675 ...\n $ seed     : int [1:626] 10403 428 437746695 -1526195747 1658218196 2037500410 309503301 -922717793 51483430 1926458288 ...\n $ statistic:function (x, idx)  \n $ sim      : chr \"ordinary\"\n $ call     : language boot(data = c(sample1, sample2), statistic = boot.func, R = R, strata = ind, weights = weights)\n $ ",
        "stype    : chr \"i\"\n $ strata   : num [1:214] 1 1 1 1 1 1 1 1 1 1 ...\n $ weights  : num [1:214] 0.00685 0.00685 0.00685 0.00685 0.00685 ...\n $ student  : logi FALSE\n - attr(*, \"class\")= chr \"simpleboot\"\n - attr(*, \"boot_type\")= chr \"boot\"\n",
        "> ",
        "",
        "> ",
        "hist(pen_boot$t, ",
        "+ ",
        "     main= \"Histogram of 10000 bootstrap replicates",
        "+ ",
        "     of the differences in mean flipper length\",",
        "+ ",
        "     xlab= \"Difference in mean flipper length (mm)\")",
        "> ",
        "",
        "> ",
        "quantile(pen_boot$t, c(0.025, 0.975))",
        "      2.5%      97.5% \n-0.4426163  0.1464300 \n",
        "> ",
        "",
        "> ",
        "mean(pen_boot$t)",
        "[1] -0.1497656\n",
        "> ",
        "",
        "> ",
        "median(pen_boot$t)",
        "[1] -0.1492279\n",
        "> ",
        "",
        "> ",
        "sd(pen_boot$t)",
        "[1] 0.1509533\n",
        "> ",
        "",
        "> ",
        "#     Questions 5-7",
        "> ",
        "pen_ecdf <- ecdf(pen_boot$t)",
        "> ",
        "pen_ecdf(pen_boot$t >= -4.5)",
        "   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [49] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [97] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [145] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [193] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1",
        " 1\n [241] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [289] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [337] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [385] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [433] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1",
        " 1 1\n [481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [529] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [577] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [625] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [673] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1",
        " 1 1 1\n [721] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [769] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [817] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [865] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [913] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1",
        " 1 1 1 1\n [961] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [ reached getOption(\"max.print\") -- omitted 9000 entries ]\n",
        "> ",
        "",
        "> ",
        "pen_ecdf(pen_boot$t <= -8)",
        "   [1] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n  [14] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n  [27] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n  [40] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n  [53] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n  [66] 0.8415 0.8415 0.8415",
        " 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n  [79] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n  [92] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [105] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [118] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [131] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415",
        " 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [144] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [157] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [170] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [183] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [196] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415",
        " 0.8415 0.8415\n [209] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [222] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [235] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [248] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [261] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [274] 0.8415",
        " 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [287] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [300] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [313] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [326] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [339] 0.8415 0.8415 0.8415 0.8415 0.8415",
        " 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [352] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [365] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [378] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [391] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [404] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415",
        " 0.8415 0.8415 0.8415 0.8415\n [417] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [430] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [443] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [456] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [469] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415",
        "\n [482] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [495] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [508] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [521] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [534] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [547] 0.8415 0.8415 0.8415",
        " 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [560] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [573] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [586] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [599] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [612] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415",
        " 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [625] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [638] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [651] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [664] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [677] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415",
        " 0.8415 0.8415\n [690] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [703] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [716] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [729] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [742] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [755] 0.8415",
        " 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [768] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [781] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [794] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [807] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [820] 0.8415 0.8415 0.8415 0.8415 0.8415",
        " 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [833] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [846] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [859] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [872] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [885] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415",
        " 0.8415 0.8415 0.8415 0.8415\n [898] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [911] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [924] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [937] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [950] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415",
        "\n [963] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [976] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [989] 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415 0.8415\n [ reached getOption(\"max.print\") -- omitted 9000 entries ]\n",
        "> ",
        "",
        "> ",
        "#     Question 9",
        "> ",
        "",
        "> ",
        "head(veg_dat)",
        "  block plot date treatment birch pine fern\n1     A   A3 1995   control     0    4  260\n2     A   A7 1995   control     0    0  186\n3     A   A4 1995   removed     8    8   46\n4     A   A6 1995   removed     6   28    1\n5     A   A5 1995     mixed     0    1  309\n6     A   A8 1995     mixed     0    0  258\n",
        "> ",
        "no_removed = na.omit(droplevels(",
        "+ ",
        "  subset(veg_dat, treatment != \"removed\")))",
        "> ",
        "control_clipped = na.omit(droplevels(",
        "+ ",
        "  subset( no_removed, treatment != \"mixed\")))",
        "> ",
        "",
        "> ",
        "wilcox.test(control_clipped$pine, na.rm= TRUE)",
        "\n\tWilcoxon signed rank test with continuity correction\n\ndata:  control_clipped$pine\nV = 78, p-value = 0.002507\nalternative hypothesis: true location is not equal to 0\n\n",
        "Warning messages:\n",
        "1: ",
        "In wilcox.test.default(control_clipped$pine, na.rm = TRUE) :",
        "\n ",
        " cannot compute exact p-value with ties\n",
        "2: ",
        "In wilcox.test.default(control_clipped$pine, na.rm = TRUE) :",
        "\n ",
        " cannot compute exact p-value with zeroes\n",
        "> ",
        "",
        "> ",
        "#     Question 10 and 11",
        "> ",
        "control= subset(control_clipped, treatment== \"control\")",
        "> ",
        "clipped= subset(control_clipped, treatment== \"clipped\")",
        "> ",
        "",
        "> ",
        "p= rnorm(control$pine)",
        "> ",
        "q= rnorm(clipped$pine)",
        "> ",
        "",
        "> ",
        "tree_boot= two.boot(p, q, ",
        "+ ",
        "                    FUN = mean,",
        "+ ",
        "                    R = 10000,",
        "+ ",
        "                    na.rm= TRUE)",
        "> ",
        "",
        "> ",
        "quantile(tree_boot$t, c(0.025, 0.975))",
        "     2.5%     97.5% \n0.1976785 1.7105153 \n",
        "> ",
        "",
        "> ",
        "boot.ci(tree_boot)",
        "BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 10000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = tree_boot)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.1969,  1.7126 )   ( 0.2061,  1.7221 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.1965,  1.7125 )   ( 0.1713,  1.6855 )  \nCalculations and Intervals on Original Scale\n",
        "Warning message:\n",
        "In boot.ci(tree_boot) :",
        "\n ",
        " bootstrap variances needed for studentized intervals\n",
        "> ",
        "quantile(tree_boot$t, c(0.025, 0.975))",
        "     2.5%     97.5% \n0.1976785 1.7105153 \n",
        "> ",
        "",
        "> ",
        "#     Question 12/13",
        "> ",
        "dat_all = merge(",
        "+ ",
        "  bird_dat, ",
        "+ ",
        "  hab_dat,",
        "+ ",
        "  by = c(\"basin\", \"sub\"))",
        "> ",
        "",
        "> ",
        "head(dat_all[, c(\"b.sidi\", \"s.sidi\")])",
        "      b.sidi s.sidi\n1 0.06678912   0.12\n2 0.06509689   0.34\n3 0.06092608   0.78\n4 0.06012721   0.57\n5 0.04112905   0.84\n6 0.06086158   0.73\n",
        "> ",
        "",
        "> ",
        "b_sidi_mean = mean(dat_all$b.sidi, na.rm = TRUE)",
        "> ",
        "b_sidi_sd   = sd(dat_all$b.sidi, na.rm = TRUE)",
        "> ",
        "",
        "> ",
        "dat_all$b.sidi.standardized = ",
        "+ ",
        "  (dat_all$b.sidi - b_sidi_mean)/b_sidi_sd",
        "> ",
        "mean(dat_all$b.sidi.standardized)",
        "[1] 7.166938e-17\n",
        "> ",
        "sd(dat_all$b.sidi.standardized)",
        "[1] 1\n",
        "> ",
        "",
        "> ",
        "s_sidi_mean = mean(dat_all$s.sidi, na.rm = TRUE)",
        "> ",
        "s_sidi_sd   = sd(dat_all$s.sidi, na.rm = TRUE)",
        "> ",
        "",
        "> ",
        "dat_all$s.sidi.standardized = (dat_all$s.sidi - s_sidi_mean)/s_sidi_sd",
        "> ",
        "mean(dat_all$s.sidi.standardized)",
        "[1] 2.984718e-17\n",
        "> ",
        "sd(dat_all$s.sidi.standardized)",
        "[1] 1\n",
        "> ",
        "",
        "> ",
        "#     Question 14 and 15",
        "> ",
        "fit_1 = lm(b.sidi ~ s.sidi, data = dat_all)",
        "> ",
        "coef(fit_1)",
        "(Intercept)      s.sidi \n 0.07116980 -0.02437131 \n",
        "> ",
        "",
        "> ",
        "slope_observed = coef(fit_1)[2]",
        "> ",
        "",
        "> ",
        "dat_1 = ",
        "+ ",
        "  subset(",
        "+ ",
        "    dat_all,",
        "+ ",
        "    select = c(b.sidi, s.sidi))",
        "> ",
        "",
        "> ",
        "set.seed(123)",
        "> ",
        "index_1 = sample(nrow(dat_1), replace = TRUE)",
        "> ",
        "index_2 = sample(nrow(dat_1), replace = TRUE)",
        "> ",
        "",
        "> ",
        "dat_resampled_i = ",
        "+ ",
        "  data.frame(",
        "+ ",
        "    b.sidi = dat_1$b.sidi[index_1],",
        "+ ",
        "    s.sidi = dat_1$s.sidi[index_2]",
        "+ ",
        "  )",
        "> ",
        "",
        "> ",
        "fit_resampled_i = lm(b.sidi ~ s.sidi, data = dat_resampled_i)",
        "> ",
        "slope_resampled_i = coef(fit_resampled_i)[2]",
        "> ",
        "",
        "> ",
        "print(slope_resampled_i)",
        "     s.sidi \n0.006235381 \n",
        "> ",
        "",
        "> ",
        "m=10000",
        "> ",
        "result_mc= numeric(m)",
        "> ",
        "",
        "> ",
        "for(i in 1:m)",
        "+ ",
        "{",
        "+ ",
        "  index_1 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  index_2 = sample(nrow(dat_1), replace = TRUE)",
        "+ ",
        "  ",
        "+ ",
        "  dat_resampled_i = ",
        "+ ",
        "    data.frame(",
        "+ ",
        "      b.sidi = dat_1$b.sidi[index_1],",
        "+ ",
        "      s.sidi = dat_1$s.sidi[index_2]",
        "+ ",
        "    )",
        "+ ",
        "  ",
        "+ ",
        "  fit_resampled_i = lm(b.sidi ~ s.sidi, data = dat_resampled_i)",
        "+ ",
        "  slope_resampled_i = coef(fit_resampled_i)[2]",
        "+ ",
        "  ",
        "+ ",
        "  slope_observed = coef(fit_1)[2]",
        "+ ",
        "  ",
        "+ ",
        "  result_mc[i] = coef(fit_resampled_i)[2]",
        "+ ",
        "} ",
        "\nRestarting R session...\n\n\nRestarting R session...\n\n"
    ]
}